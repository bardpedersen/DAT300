{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NB\n",
    "- You might need to run `pip install tensorflow-addons` ´to use  `f1_score`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compulsory Assignment 2: Convolutional neural networks\n",
    "\n",
    "Please fill out the the group name, number, members and optionally the name below.\n",
    "\n",
    "**Group number**: \\\n",
    "**Group member 1**: \\\n",
    "**Group member 2**: \\\n",
    "**Group member 3**: \\\n",
    "**Group name (optional)**: \n",
    "\n",
    "Make sure that the group name given in the assignment is the same that you use on the Kaggle Leaderboard.\n",
    "\n",
    "# Assignment Submission\n",
    "To complete this assignment answer the relevant questions in this notebook and write the code required to implement the relevant models. The assignment is submitted by handing in this notebook as an .ipynb file and as a .pdf file. In addition, you are required to submit at least one test prediction to the Kaggle leaderboard that is better than the *BEAT ME* score.\n",
    "\n",
    "NOTE: Remember to go through the rules given in the lecture \"Introduction to compulsory assignments\", as there are many do's and dont's with regard to how you should present the work you are going to submit. \n",
    "\n",
    "# Introduction \n",
    "This assignment will start with classifying handwritten digits from the MNIST dataset, used in the voluntary assignment and the first compulsory assignment. The second part of this task will revolve around classifying the open-source Fashion-MNIST dataset.\n",
    "\n",
    "\n",
    "\n",
    "## Fashion-MNIST\n",
    "\n",
    "The Fashion-MNIST is a dataset created from Zlalando's articile images(https://github.com/zalandoresearch/fashion-mnist/blob/master/README.md). The dataset consits of 70,000 labels images in 28x28 grayscale image labeld from 0 to 10. The goal of the Fashion-MNIST to work as a harder version of the handletter dataset MNIST. The Github repo for the dataset descripte the dataset to be:\n",
    "- \"intend Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms.\"\n",
    "\n",
    "\n",
    "<center><img src=\"fashion-mnist-sprite.png\" width=\"500\" height=\"400\"></center>\n",
    "\n",
    "\n",
    "## Assignment structure\n",
    "\n",
    "1. Part 1: Implementing LeNet5 for classifying MNIST.\n",
    "2. Part 2: Designing your own CNN for classifying Fashion-MNIST\n",
    "\n",
    "## Submissions to the Kaggle leaderboard\n",
    "Use the following code to create the `submission.csv` file that you can submit to the Kaggle leaderboard. \n",
    "\n",
    "```python\n",
    "prediction = model.predict(X_test)\n",
    "flat_prediction = np.argmax(prediction, axis=1) # Flatten softmax predictions\n",
    "submissionDF = pd.DataFrame()\n",
    "submissionDF['ID'] = range(len(flat_prediction)) # The submission csv file must have an row index column called 'ID'\n",
    "submissionDF['Prediction'] = flat_prediction\n",
    "submissionDF.to_csv('submission.csv', index=False) # Remember to store the dataframe to csv without the nameless index column.\n",
    "```\n",
    "\n",
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to add or remove libraries as you want\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow.keras as ks\n",
    "\n",
    "SEED = 458\n",
    "RNG = np.random.default_rng(SEED) # Random number generator\n",
    "\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: CNN for classifying the MNIST dataset\n",
    "\n",
    "## Loading MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = load_mnist(verbose=0)\n",
    "X_train, y_train = datasets['X_train'], datasets['y_train']\n",
    "X_val,   y_val   = datasets['X_val'],   datasets['y_val']\n",
    "X_test,  y_test  = datasets['X_test'],  datasets['y_test']\n",
    "\n",
    "X_train = np.concatenate([X_train, X_val], axis=0)\n",
    "y_train = np.concatenate([y_train, y_val], axis=0).astype('int32')\n",
    "\n",
    "del datasets, X_val, y_val # Good to reduce uneccesary RAM usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data to account for color channel\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test  = np.expand_dims(X_test, -1)\n",
    "\n",
    "# Normalizing input between [0,1]\n",
    "X_train = X_train.astype(\"float32\")/np.max(X_train)\n",
    "X_test  = X_test.astype(\"float32\")/np.max(X_test)\n",
    "\n",
    "# Converting targets from numbers to categorical format\n",
    "y_train = ks.utils.to_categorical(y_train, len(np.unique(y_train)))\n",
    "y_test  = ks.utils.to_categorical(y_test, len(np.unique(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.1: Build a CNN network with the LeNet5 architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implement LeNent5 architecture according to the following specifications: \n",
    "\n",
    "--------------------------\n",
    "The LeNet architecture takes a 28x28xC image as input, where C is the number of color channels. Since MNIST images are grayscale, C is 1 in this case.\n",
    "\n",
    "**Layer 1 - Convolution (5x5):** The output shape should be 28x28x6. **Activation:** ReLU. \n",
    "\n",
    "**MaxPooling:** The output shape should be 14x14x6.\n",
    "\n",
    "**Layer 2 - Convolution (5x5):** The output shape should be 10x10x16. **Activation:** ReLU. \n",
    "\n",
    "**MaxPooling:** The output shape should be 5x5x16.\n",
    "\n",
    "**Flatten:** Flatten the output shape of the final pooling layer such that it's 1D instead of 3D.  You may need to use tf.reshape.\n",
    "\n",
    "**Layer 3 - Fully Connected:** This should have 120 outputs. **Activation:** ReLU.\n",
    "\n",
    "**Layer 4 - Fully Connected:** This should have 84 outputs. **Activation:** ReLU.\n",
    "\n",
    "**Layer 5 - Fully Connected:** This should have 10 outputs. **Activation:** softmax.\n",
    "\n",
    "--------------------------\n",
    "\n",
    "\n",
    "##### Compile the network with the\n",
    "* `tf.keras.losses.CategoricalCrossentropy` loss function\n",
    "* the `adam` optimizer \n",
    "* with the `accuracy` metric and (your own implementation of the) F1-score metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1.2 Train network\n",
    "\n",
    "Train the network with a \n",
    "* batch size of 64 samples\n",
    "* for 20 epochs\n",
    "* 1/8 validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.2 Evaluaiton\n",
    "### Task 1.2.1 Plot training history and evaluate on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2.2 Evaluate on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2.3 Create a confution matrix for both traing and testing data\n",
    "- Does the test data and train data predikt the same items wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.3: MNIST discussion\n",
    "\n",
    "**Task 2.3.1: What is overfititng and how does it ocure during training of the LeNet-5 model**\n",
    "\n",
    "**Task 2.3.2: What is ReLU and Leaky ReLU, what is their derivative and how does their derative solve the vanesting gradient problem?**\n",
    "\n",
    "**Task 2.3.3: Calculate the Number of Trainable Parameters and the Output Shape of Feature Maps for LeNet-5 at Each Layer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: CNN for classifying the Fashion-MNIST dataset\n",
    "\n",
    "In this task you shall implement a CNN model, and train it to classify the images in the Fashion-MNIST dataset.\n",
    "\n",
    "## Importing Fashion-MNIST\n",
    "\n",
    "- Filename: `Fashion_MNIST.h5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = \"Fashion_MNIST.h5\" # If data is in same directory as Jypyter File\n",
    "\n",
    "labels = {\n",
    "    0: \"T-shirt/top\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle boot\" \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets in file: ['test_images', 'train_images', 'train_labels']\n",
      "Nr. train images: 59500\n",
      "Nr. test images: 10500\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(FILE_PATH,'r') as f:\n",
    "    print('Datasets in file:', list(f.keys()))\n",
    "    X_train = np.asarray(f['train_images'])\n",
    "    y_train = np.asarray(f['train_labels'])\n",
    "    X_test  = np.asarray(f['test_images'])\n",
    "    print('Nr. train images: %i'%(X_train.shape[0]))\n",
    "    print('Nr. test images: %i'%(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1: Preprocess the data\n",
    "Preprocess the data as you see fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.2: Visualize the dataset\n",
    "Plot a few samples images and the distrbution of classes in the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.3: Build a CNN for Classifying the Fashion-MNIST Dataset\n",
    "Build a CNN model and beat the \"Beat Me\" score on Kaggle.\n",
    "\n",
    "- Experiment with different kernel sizes, strides, and types/number of layers.\n",
    "- Don’t overcomplicate it; focues on as grounds for discussion when you make the models.\n",
    "Tips: When you make changes to the model, save some earlier iterations.\n",
    "You need only one model scored higher than \"Beat Me.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.4: Evaluate your best model on the test dataset and submit your prediction to the Kaggle leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kaggle_model_prediction = Kaggle_model.predict(X_test)\n",
    "flat_Kaggle_model_prediction_prediction = np.argmax(Kaggle_model_prediction, axis=1)\n",
    "submissionKaggle = pd.DataFrame()\n",
    "submissionKaggle['ID'] = range(len(flat_Kaggle_model_prediction_prediction))\n",
    "submissionKaggle['Prediction'] = flat_Kaggle_model_prediction_prediction\n",
    "submissionKaggle.to_csv('KaggelSubmission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.5: Fashion-MNIST Discussion\n",
    "\n",
    "### Task 3.5.1\n",
    "- Feel Free to experimant on acitecture\n",
    "- Comment on the choice of layers and hyper paramters. \n",
    "    - Did you find some different results in changing a hyer paramter or add/remove a layer.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dat300_TA2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
