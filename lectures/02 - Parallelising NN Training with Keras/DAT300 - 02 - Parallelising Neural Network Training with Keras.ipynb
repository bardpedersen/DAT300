{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "8b0d1366-6552-473d-9e29-2a9b1f283b8e"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parallelising Neural Network Training with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ae7b2481-86af-4893-9753-02475b283430"
    }
   },
   "source": [
    "<img src=\"./images/keras_tensorflow.jpg\" width=\"350\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ace66a88-c671-483a-b49c-346b26ac7601"
    }
   },
   "source": [
    "**Note**: This notebook is adapted from chapter 13 in *Python Machine Learning* book, using Keras instead of TensorFlow. This notebook contains also (many) elements of book [*Deep Learning with Python*](https://www.manning.com/books/deep-learning-with-python), chapter 3 and 4. The Keras code is stored [here](https://github.com/fchollet/deep-learning-with-python-notebooks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TensorFlow is a Python-based, free, **open-source machine learning platform**, developed primarily by **Google**\n",
    "* Much like NumPy, the primary purpose of TensorFlow is to **enable engineers and researchers** to manipulate **mathematical expressions** over **numerical tensors**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "TensorFlow goes **far beyond** the scope of NumPy in the following ways\n",
    "* It can **automatically compute** the gradient of any differentiable expression, making it highly suitable for machine learning\n",
    "* It can run not only on **CPU**, but also on **GPUs** and **TPUs**, highly-parallel hardware accelerators\n",
    "* Computation defined in TensorFlow can be **easily distributed across many machines**\n",
    "* TensorFlow programs can be **exported to other runtimes**, such as \n",
    "    * C++, JavaScript (for browser-based applications), or \n",
    "    * TFLite (for applications running on mobile devices or embedded devices), etc. \n",
    "* This makes TensorFlow applications **easy to deploy** in practical settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "91436083-c317-4bd4-ac12-e280a2298e95"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Keras is a deep-learning API for Python, built **on top of** TensorFlow\n",
    "* Provides a **convenient** way to define and train any kind of deep-learning model\n",
    "* Initially developed for research, with the aim of enabling **fast deep learning experimentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./images/fig_3.1.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] *F. Chollet*, Deep Learning with Python, 2nd Ed., chapter 3.1, Fig. 3.1.\n",
    "\n",
    "Keras and TensorFlow: TensorFlow is a low-level tensor computing platform, Keras is a high-level deep learning API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "bd4a1fe5-bba1-4c90-b406-d17801ea6257"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Run Keras**\n",
    "\n",
    "* **locally** (on CPUs on your own PC; on GPU on your own gaming PC): \n",
    "    - It is likely that your laptop doesn't have a graphical processing unit (GPU) suitable for use deep learning computations.\n",
    "    - This will result in longer training times for your model using only CPUs, but may be the only feasable option if you need to work offline.\n",
    "\n",
    "\n",
    "* **in the cloud** using [Google Colaboratory](https://colab.research.google.com/notebooks/welcome.ipynb) or [Kaggle](https://www.kaggle.com/notebooks) \n",
    "     - This requires internet connection and a Google / Kaggle account. \n",
    "     - You will have access to an outdated GPU "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Other deep learning libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [PyTorch](https://pytorch.org/) (by Facebook)\n",
    "* [Caffe](http://caffe.berkeleyvision.org/)\n",
    "* ... and many more\n",
    "* [Overview on Wiki](https://en.wikipedia.org/wiki/Comparison_of_deep-learning_software)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "5d255640-4e48-48fe-9a93-788a8145ad18"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "6b1c5938-5349-4c06-9d37-56c080176d4e"
    }
   },
   "source": [
    "- [For the unpatient - a quick look at a neural network built with Keras](#For-the-unpatient---a-quick-look-at-a-neural-network-built-with-Keras) - contains <font color=green>**COLAB NOTEBOOK 00**</font>\n",
    "- [Data representations for neural networks](#Data-representations-for-neural-networks) - contains <font color=green>**COLAB NOTEBOOK 01**</font>\n",
    "    - [Vector data](#Vector-data)\n",
    "    - [Time series or sequence data](#Time-series-or-sequence-data)\n",
    "    - [Image data](#Image-data)\n",
    "    - [Video data](#Video-data)\n",
    "- [Introduction to Keras](#Introduction-to-Keras)\n",
    "    - [Binary classification - Classifying movie reviews](#Binary-classification---Classifying-movie-reviews) - contains <font color=green>**COLAB NOTEBOOK 02**</font>\n",
    "    - [Multiclass classification - Classifying newswires](#Multiclass-classification---Classifying-newswires) - contains <font color=green>**COLAB NOTEBOOK 03**</font>\n",
    "    - [Regression - Predicting house prices](#Regression---Predicting-house-prices) - contains <font color=green>**COLAB NOTEBOOK 04**</font>\n",
    "- [Overfitting and underfitting: regularisation methods for ANN](#Overfitting-and-underfitting:-regularisation-methods-for-ANN) - contains <font color=green>**COLAB NOTEBOOK 05**</font>\n",
    "- [Choosing activation functions for multilayer networks](#Choosing-activation-functions-for-multilayer-networks)\n",
    "- [Vanishing gradient problem](#Vanishing-gradient-problem)\n",
    "- [Loss function: Cross entropy](#Loss-function:-Cross-entropy)\n",
    "- [Summary](#Summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "973a0b6c-c02a-47cf-93d6-214574b216aa"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## For the unpatient - a quick look at a neural network built with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ab731075-b032-4850-8674-3c23c9da71ee"
    }
   },
   "source": [
    "* Build our first neural network using the Keras library\n",
    "* More details on Keras later in this notebook\n",
    "* <font color=green>**COLAB NOTEBOOK 00**</font>: Data used in this [first example](https://colab.research.google.com/drive/1iG3Gg8-vqVufeCaAgQz9spWFWdp67pDP?usp=sharing): MNIST data (full set) of handwritten digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "7c91e9a7-bb8e-4e36-a43b-9e6010a5bbb1"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data representations for neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f8eee3fe-ea93-40ec-87cb-9eb5c9366818"
    }
   },
   "source": [
    "* Previous example used data stored in multidimensional Numpy arrays, also called **tensors**.\n",
    "* **All machine learning systems** use tensors as their basic data structure\n",
    "* Tensors are fundamental to the field of machine learning - TensorFlow was named after them\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "a1740ba8-51b2-42bd-a359-cda3e52e5b2c"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* What are tensors?\n",
    "    - tensors are *containers for data* (almost always numerical data)\n",
    "    - tensors are a *generalisation of matrices* to an *arbitrary* number of dimensions\n",
    "    - a *dimension* is often called an axis in the context of tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "50663c88-366d-42f7-9682-416c89ecc6ab"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Vector data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "c3c7292b-72ea-4819-85f0-c4ad9868a127"
    }
   },
   "source": [
    "* This is the most common case\n",
    "* In such a dataset, each single data point can be encoded as a vector.\n",
    "* Thus a batch of data will be encoded as a 2D tensor (array of vectors)\n",
    "* 2D tensor: first axis is the *samples axis* and the second axis is the *features axis*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "3c3b3a07-b081-4242-aeff-719ac5f10779"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Vector data -  Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "8435301b-e916-4f7d-9f06-db9e144a15db"
    }
   },
   "source": [
    "Actuarial dataset of people considering:\n",
    "* persons age\n",
    "* ZIP code\n",
    "* income\n",
    "\n",
    "Each person can be characterised as a vector of 3 values. A dataset of 100 000 people could be stored in a 2D tensor of shape `(100000, 3)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "98a413df-6017-426c-8195-e42bc6960066"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Vector data -  Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "e9c4367b-ab75-4e1d-917c-eeb97d1ce379"
    }
   },
   "source": [
    "A dataset of text documents, where each document is represented by counts of how many times each word appears in it (out of a dictionary of 20 000 common words).\n",
    "\n",
    "* Each document can be considered as a vector of 20 000 values\n",
    "\n",
    "If dataset consists of 500 documents, data could be stored in a 2D tensor of shape `(500, 20000)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d6aa12d3-f86f-4aed-85ba-b45b271e0ff9"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Time series or sequence data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "56cf3bdb-8807-4a69-b91a-9bd3a4e28aee"
    }
   },
   "source": [
    "* Whenever time matters in your data (or the notion of sequence order), it makes sense to store it in a 3D tensor with an **explicit time axis**\n",
    "* Each sample can be encoded as a sequence of vectors (a 2D tensor)\n",
    "* Thus a batch of data will be encoded as a 3D tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "9a5c8ddf-f99e-4812-b84b-908dfa13158d"
    }
   },
   "source": [
    "<img src=\"./images/fig_2.3.png\" width=\"350\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "c79c36f6-f25e-416b-a4c2-9959b450ec76"
    }
   },
   "source": [
    "[1] *F. Chollet*, Deep Learning with Python, chapter 2.2.10, Fig. 2.3. **A 3D timeseries data tensor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "9f0d4d76-1b38-41dc-b649-ea678e106103"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Timeseries data -  Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "167c6d03-7836-4ca0-adc7-3b63b0acadc9"
    }
   },
   "source": [
    "A dataset of stockprices:\n",
    "\n",
    "* record current price of stock\n",
    "* record highest price in past minute\n",
    "* record lowest price in past minute\n",
    "\n",
    "Given a total of 390 minutes in a trading day, the data of one trading day will be stored in a 2D tensor of shape `(390 x 3)`. If there are 250 days of trading in one year then the data may be stored in a 3D tensor of shape `(250, 390, 3)`. In this case each sample would be the data of one trading day. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1b74754a-26c7-42b3-b03e-80c8870660bc"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Sequence data -  Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2831dfbb-a501-4567-a642-6cd3df6a7915"
    }
   },
   "source": [
    "A dataset of tweets:\n",
    "\n",
    "* encode each tweet as a sequence of 280 characters out of an alphabet of 128 unique characters\n",
    "* each character can be encoded as a binary vector of size 128 (an all-zeros vector except for a 1 entry at the index corresponding to the character)\n",
    "\n",
    "Each tweet can be encoded as a 2D tensor of shape `(280, 128)`. Hence, a dataset of 1 million tweets can be stored in a 3D tensor of shape `(1000000, 280, 128)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "33207130-bf00-49d1-bbc6-19decbf10acf"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Image data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "e8ba5365-53d6-43d6-b69a-25c04ef96f59"
    }
   },
   "source": [
    "* Images typically have three dimensions: height, width and colour depth\n",
    "* Although grayscale images (like our MNIST digits) have only a single color channel and could thus be stored in 2D tensors, by convention image tensors are always 3D, with a onedimensional color channel for grayscale images\n",
    "\n",
    "A batch of 128 grayscale images of size 256 × 256 could thus be stored in a tensor of shape `(128, 256, 256, 1)`. A\n",
    "batch of 128 color images could be stored in a tensor of shape `(128, 256, 256, 3)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "686a5e30-6e1a-426e-8846-d8d613c6e283"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./images/fig_2.4.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "8d561117-d8c0-424f-acbd-22971b80bd6c"
    }
   },
   "source": [
    "[1] *F. Chollet*, Deep Learning with Python, chapter 2.2.11, Fig. 2.4. **A 4D image data tensor (channel-first convention)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "306581a5-3681-422d-b927-114f977c0b0e"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Two conventions** for shapes of image tensors:\n",
    "* *channel-last* convention as used by TensorFlow `(samples, height, width, color_depth)`\n",
    "* *channel-first* convention as used by Theano `(samples, color_depth, height, width)`\n",
    "* Either, TensorFlow or Theano, may be used as the engine for Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "32922d54-f09b-4685-9338-49c4ddc6a5d7"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Video data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "5b64dd29-f187-46a8-829d-4b03149ca893"
    }
   },
   "source": [
    "* Video data is one of the few types of real-world data for which you’ll need 5D tensors\n",
    "* A video can be understood as a sequence of frames, each frame being a color image\n",
    "* Because each frame can be stored in a 3D tensor `(height, width, color_depth)`, a sequence of frames can be stored in a 4D tensor `(frames, height, width, color_depth)`\n",
    "* Thus a batch of **different videos** can be stored in a 5D tensor of shape `(samples, frames, height, width, color_depth)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ffdef7ad-ecbd-48e0-943a-4db221e2e056"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Video data - Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "e287bf1b-68af-4a6e-939f-8b5665d35eb1"
    }
   },
   "source": [
    "Imagine you have a video with the following properties:\n",
    "\n",
    "* 60 second video\n",
    "* 144 x 256 (height, width)\n",
    "* 4 frames per second\n",
    "\n",
    "A batch of **four** such video clips would be stored in a tensor of shape `(4, 240, 144, 256, 3)`. That’s a total of 106 168 320 values! If the `dtype` of the tensor was `float32`, then each value would be stored in 32 bits, so the tensor would represent 405 MB, which is quite a lot. Videos in real life are much lighter, because they aren’t stored in `float32`, and they’re typically compressed by a large factor (such as in the MPEG format)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "cad9e55a-f576-49d1-88a3-197af6f2cf64"
    }
   },
   "source": [
    "<font color=green>**COLAB NOTEBOOK 01**</font>: code on [use of tensors](https://colab.research.google.com/drive/1Ti5xgYJyeMmesZ8vTKCm2L0JeSwNFmsG?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1970300c-a616-41de-ba29-ca3bb2b83b82"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction to Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ac168c6c-bf66-4d47-ae8a-ad02145d64b9"
    }
   },
   "source": [
    "This section covers:\n",
    "* Core components of neural networks\n",
    "* An introduction to Keras\n",
    "* Using neural networks to solve basic classification and regression problems\n",
    "\n",
    "\n",
    "* Three introductory examples of how to use neural networks to address real problems\n",
    "    - Classifying movie reviews as **positive** or **negative** (binary classification)\n",
    "    - Classifying news wires by **topic** (multiclass classification)\n",
    "    - Estimating the **price of a house**, given real-estate data (regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2fcb1632-c60f-46ad-8b54-172992f4ae0c"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Anatomy of a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f808aaaa-cb10-4f61-9b98-2a3eb179dddd"
    }
   },
   "source": [
    " training a neural network revolves around the following objects:\n",
    "\n",
    "1. **Layers**, which are combined into a network (or model)\n",
    "2. The **input data** and **corresponding targets**\n",
    "3. The **loss function**, which defines the feedback signal used for learning\n",
    "4. The **optimizer**, which determines how learning proceeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "022709f7-59a6-4e48-a210-43c28a4c8ce9"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./images/ANN.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d23127c7-063e-4732-b1f0-ae0d6c022393"
    }
   },
   "source": [
    "[1] *F. Chollet*, Deep Learning with Python, chapter 3.1, Fig. 3.1. **Relationship between the network, layers, loss function and optimiser.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Layers: the building blocks of deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Layers are a fundamental data structure in neural networks\n",
    "* A layer is a data-processing module that takes as input one or more tensors and that outputs one or more tensors\n",
    "* The layer’s **weights** contain the network’s **knowledge**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Types of layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Different layers are appropriate for different tensor formats and different types of data\n",
    "processing. For instance:\n",
    "\n",
    "* *simple vector data*, stored in 2D tensors of shape `(samples, features)`, is often processed by **densely** connected layers\n",
    "    - also called **fully** connected or **dense layers**\n",
    "    - represented by `Dense` class in Keras\n",
    "* *sequence data*, stored in 3D tensors of shape `(samples, timesteps, features)`, is typically processed by **recurrent layers** such as an `LSTM` layer\n",
    "* *Image data*, stored in 4D tensors, is usually processed by 2D **convolution layers** (`Conv2D`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Layers are the LEGO bricks of deep learning, a metaphor that is made explicit by frameworks like Keras\n",
    "* Building deep-learning models in Keras is done by clipping together **compatible layers** to form useful **data-transformation** pipelines.\n",
    "* The notion of **layer compatibility** here refers specifically to the fact that every layer will only accept **input tensors** of a **certain shape** and will return **output tensors** of a certain shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Code implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "layer = layers.Dense(32, activation='relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a layer that accepts only 2D tensors (remember, that's what `Dense` layers do)\n",
    "* The `Dense` layer has `32` output or activation units\n",
    "* The first dimension of the 2D tensor is `784` (axis 0, the **batch dimension**, is unspecified, and thus any value would be accepted)\n",
    "* This layer will return a tensor where the first dimension has been transformed to be `32`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Code implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* With Keras, there is no reason to worry about compatibility, because the layers added to the models are **dynamically built** to **match the shape** of the **incoming layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(32)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Models: networks of layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A deep-learning model is a directed, acyclic graph of layers\n",
    "* The most common instance is a linear stack of layers, mapping a single input to a single output\n",
    "*  There is a broader variety of network topologies. Some common ones include the following:\n",
    "    - Two-branch networks\n",
    "    - Multihead networks\n",
    "    - Inception blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The **topology** of a network defines a **hypothesis space**\n",
    "* By choosing a network topology, you **constrain** your space of possibilities (hypothesis space) to a specific **series of tensor operations**, mapping input data to output data\n",
    "*  Picking the right network architecture is more an **art** than a **science**\n",
    "*  Although there are some best practices and principles you can rely on, **only practice** can help you become a proper neural-network architect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Loss functions and optimizers: keys to configuring the learning process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the network architecture is defined, there are two more things that need to be defined.\n",
    "\n",
    "* **Loss function** (**objective function**): the quantity that will be minimized during training. It represents a measure of success for the task at hand\n",
    "* **Optimizer**: determines how the network will be updated based on the loss function. It implements a specific variant of stochastic gradient descent (SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the right objective function for the right problem is extremely important: the network will take any shortcut it can, to minimize the loss. If the objective doesn’t fully correlate with success for the task at hand, your network will end up\n",
    "doing things you may not have wanted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For common problems such as classification, regression and sequence prediction, there are simple guidelines one can follow to choose the correct loss. For instance:\n",
    "\n",
    "* **binary crossentropy** for a **two-class classification** problem\n",
    "* **categorical crossentropy** for a **many-class classification** problem\n",
    "* **mean squared error** for a **regression** problem\n",
    "* **connectionist temporal classification (CTC)** for a sequence-learning problem\n",
    "* etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only when working on truly new research problems one will have to develop own objective functions. In the next few chapters, we’ll detail explicitly which loss functions to choose for a wide range of common tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Keras workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the MNIST example we have already built our first Keras model. The general workflow is constructed like this: \n",
    "\n",
    "1. Define your training data: input tensors and target tensors.\n",
    "2. Define a network of layers (or model ) that maps your inputs to your targets.\n",
    "3. Configure the learning process by choosing a loss function, an optimizer, and some metrics to monitor.\n",
    "4. Iterate on your training data by calling the `fit()` method of your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Defining a Keras model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to define a Keras model:\n",
    "\n",
    "1. using the `Sequential` class (only for linear stacks of layers, which is the most common network architecture by far)\n",
    "2. using the *functional* API (for directed acyclic graphs of layers, which lets you build completely arbitrary architectures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here’s a two-layer model defined using the `Sequential` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(32)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Once your model architecture is defined, it doesn’t matter whether you used a `Sequential` model or the functional API. All of the following steps are the same. The learning process is configured in the compilation step, where you specify:\n",
    "\n",
    "* *Loss function (objective function)* — The quantity that will be minimized during training. It represents a measure of success for the task at hand.\n",
    "* *Optimizer* — Determines how the network will be updated based on the loss function. It implements a specific variant of stochastic gradient descent (SGD).\n",
    "* *Metrics* — The measures of success you want to monitor during training and validation, such as classification accuracy. Unlike the loss, training will not optimize directly for these metrics. As such, metrics don’t need to be differentiable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here’s an example with a single loss function, which is by far the most common case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = keras.Sequential([keras.layers.Dense(1)])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Finally, the learning process consists of passing Numpy arrays of input data (and the corresponding target data) to the model via the `fit()` method, similar to what you would do in Scikit-Learn and several other machine-learning libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model (in the same manner as you would with scikit-learn)\n",
    "model.fit(input_tensor,\n",
    "          target_tensor, \n",
    "          epochs=5\n",
    "          batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the next few chapters, you’ll build a solid intuition about what type of network architectures work for different kinds of problems, how to pick the right learning configuration, and how to tweak a model until it gives the results you want to see. We’ll look at three basic examples in sections: \n",
    "\n",
    "* a two-class classification example\n",
    "* a many-class classification example \n",
    "* a regression example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Binary classification - Classifying movie reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two-class classification, or binary classification, may be the most widely applied kind of machine-learning problem. In this example, you’ll learn to classify movie reviews as positive or negative, based on the text content of the reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>**COLAB NOTEBOOK 02**</font>: [Classifying movie reviews](https://colab.research.google.com/drive/1d17CTqADFahrrFvJFFbbvDbxwbVPxuGw?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multiclass classification - Classifying newswires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>**COLAB NOTEBOOK 03**</font>: [Classifying newswires](https://colab.research.google.com/drive/103rpmFW5laPRSRttkd5KnrEIx0JrwB-b?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Regression - Predciting house prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>**COLAB NOTEBOOK 04**</font>: [Predicting house prices](https://colab.research.google.com/drive/1_hCgKqYjxgBe2mHECK3uAyPhewm9l05k?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overfitting and underfitting: regularisation methods for ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>**COLAB NOTEBOOK 05**</font>: [Regularisation in Keras](https://colab.research.google.com/drive/17xnyr8TsZu_wF7wQZFnQ-1C9NqxkOXb9?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Choosing activation functions for multilayer networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Technically, one can use **any function** as an activation function in multilayer neural networks as long as it is **differentiable**\n",
    "* One could can even use **linear** activation functions, such as in Adaline, but ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- would **not** be very useful to use linear activation functions for both hidden and output layers \n",
    "- to tackle complex problems one needs to introduce **non-linearity**\n",
    "- the **sum of linear functions** would yield only **another** linear function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Activation Functions: Pros and Cons\n",
    "\n",
    "| **Activation Function** | **Pros**                               | **Cons**                                    |\n",
    "|-------------------------|----------------------------------------|---------------------------------------------|\n",
    "| **Linear**              | Simple, good for regression            | No non-linearity, cannot handle complex data|\n",
    "| **Unit Step**           | Simple, useful in binary classification| Not differentiable, poor for gradient-based learning |\n",
    "| **Sign**                | Easy to compute                        | Non-differentiable, limits model complexity |\n",
    "| **Piece-wise Linear**    | Used in specific algorithms (SVMs)     | More complex, limited use in neural networks|\n",
    "| **Logistic (Sigmoid)**  | Smooth output, good for probabilities  | Vanishing gradient problem, slow convergence|\n",
    "| **Tanh (Hyperbolic Tangent)** | Zero-centered output, stronger gradient | Suffers from vanishing gradients          |\n",
    "| **ReLU**                | Efficient, fast convergence, avoids vanishing gradients | Can \"die\" for negative inputs, not zero-centered |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/overview_actfunc.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* The **logistic activation function** (which we often called *sigmoid function*) mimics the concept of a neuron in a brain most closely - think of it as the probability of whether a neuron fires or not\n",
    "* However, logistic activation functions can be problematic\n",
    "    - When net input $\\textbf{z}$ is **highly negative**, $\\phi{(\\textbf{z})}$ would be close to zero\n",
    "    - If $\\phi{(\\textbf{z})}$ is close to zero the neural network would learn **very slowly**\n",
    "    - More slowly learning could lead to the neural network **getting trapped in local minima** during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Logistic function recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The **logistic function** is a special case of a **sigmoid function**\n",
    "* We can use a logistic function to model the probability that sample $\\textbf{x}$ belongs to the positive class (class 1) in a **binary classification** task\n",
    "* The net input $z$ is shown in the following equation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/netInputZ.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The logistic function will compute the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/phiOfZ.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Example using two-dimensional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(y=1|x) = 0.888\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import numpy as np\n",
    "\n",
    "# Generate some two-dimensional data including bias and weight vector w\n",
    "X = np.array([1, 1.4, 2.5]) ## first value must be 1, since it represents bias\n",
    "w = np.array([0.4, 0.3, 0.5])\n",
    "\n",
    "# Define function for computation of net input z\n",
    "def net_input(X, w):\n",
    "    return np.dot(X, w)\n",
    "\n",
    "# Define logistic function\n",
    "def logistic(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "# Define phi(z) activation function\n",
    "def logistic_activation(X, w):\n",
    "    z = net_input(X, w)\n",
    "    return logistic(z)\n",
    "\n",
    "# Compute probability of x belonging to positive class (y = 1)\n",
    "print('P(y=1|x) = %.3f' % logistic_activation(X, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "However, an output layer consisting of **multiple logistic activation units** does not produce meaningful, interpretable probability values. This is illustrated by code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net Input: \n",
      " [1.78 0.76 1.65]\n",
      "Output Units:\n",
      " [0.85569687 0.68135373 0.83889105]\n"
     ]
    }
   ],
   "source": [
    "# NOTE: This code was adapted to correspond with equations discussed in chapter 12\n",
    "\n",
    "# W : array with shape = (n_hidden_units + 1, n_output_units)\n",
    "#     note that the first row are the bias units\n",
    "W = np.array([[1.1, 0.2, 0.6],\n",
    "              [1.2, 0.4, 1.5],\n",
    "              [0.8, 1. , 1.2],\n",
    "              [0.4, 0.2, 0.7]])\n",
    "\n",
    "# A : data array with shape = (n_samples, n_hidden_units + 1)\n",
    "#     note that the first column of this array must be 1\n",
    "A = np.array([[1, 0.1, 0.4, 0.6]])\n",
    "\n",
    "# Compute net input Z and probabilities \n",
    "Z = np.dot(A[0], W)\n",
    "y_probas = logistic(Z)\n",
    "\n",
    "print('Net Input: \\n', Z)\n",
    "\n",
    "print('Output Units:\\n', y_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* The resulting values **cannot** be interpreted as **probabilities** for a three-class problem\n",
    "* The reason for this is that they **do not** sum up to 1\n",
    "* Usually, this is not of concern when we use the model to predict class membership\n",
    "* One to predict class membership is to assign sample to **maximum value** of $\\textbf{Z}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class label: 0\n"
     ]
    }
   ],
   "source": [
    "y_class = np.argmax(Z, axis=0)\n",
    "print('Predicted class label: {0}'.format(y_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* In certain contexts, it can be useful to compute meaningful class probabilities for multiclass predictions \n",
    "* In the next section, we will take a look at a **generalization** of the logistic function, the ``softmax`` function, which can help us with this task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Estimating class probabilities in multiclass classification via the ``softmax`` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In previous sections: obtain a class label using the ``argmax`` function\n",
    "* The ``softmax`` function is in fact a soft form of the ``argmax`` function; instead of giving a single class index, it provides the **probability of each class**\n",
    "* The ``softmax`` function allows for computation of **meaningful** class probabilities in **multiclass** settings (multinomial logistic regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In ``softmax``, the probability of a particular sample with net input $z$ belonging to the $i$th class can be computed with a normalization term in the denominator, that is, the sum of all $M$ linear functions.\n",
    "We do not use Softmax in hidden layers: If a hidden layer has multiple neurons, each neuron is supposed to activate independently, meaning they respond to different patterns in the input. However, if we use softmax in a hidden layer, it forces the neurons to compete with each other because their outputs must add up to 1. This would interfere with their job of learning different features from the data and limit the flexibility of the network to learn effectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/softmax_eq.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``softmax`` function coded in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities:\n",
      " [0.44668973 0.16107406 0.39223621]\n"
     ]
    }
   ],
   "source": [
    "def softmax(z):\n",
    "    return np.exp(z) / np.sum(np.exp(z))\n",
    "\n",
    "y_probas = softmax(Z)\n",
    "print('Probabilities:\\n', y_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The predicted class label is the same as when we applied the ``argmax`` function to the logistic output\n",
    "* Intuitively, it may help to think of the ``softmax`` function as a *normalized* output that is useful to obtain meaningful **classmembership predictions** in multiclass settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Broadening the output spectrum using a hyperbolic tangent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Another *sigmoid function* that is often used in the **hidden layers** of artificial neural networks is the **hyperbolic tangent** (commonly known as ``tanh``)\n",
    "* ``tanh`` can be interpreted as a rescaled version of the logistic function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/log_&_tanh.png\" width=\"700\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Advantage of the hyperbolic tangent over the logistic function**\n",
    "\n",
    "* It has a **broader output spectrum** and ranges in the **open interval** (-1, 1)\n",
    "* This can improve the convergence of the back propagation algorithm [Neural Networks for Pattern Recognition, C. M. Bishop, Oxford University Press, pages: 500-501, 1995](https://www.microsoft.com/en-us/research/wp-content/uploads/1996/01/neural_networks_pattern_recognition.pdf)\n",
    "* In contrast, the logistic function returns an output signal that ranges in the open interval (0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For an intuitive comparison of the logistic function and the hyperbolic tangent, let's plot the two sigmoid functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def tanh(z):\n",
    "    e_p = np.exp(z)\n",
    "    e_m = np.exp(-z)\n",
    "    return (e_p - e_m) / (e_p + e_m)\n",
    "\n",
    "z = np.arange(-5, 5, 0.005)\n",
    "log_act = logistic(z)\n",
    "tanh_act = tanh(z)\n",
    "\n",
    "plt.ylim([-1.5, 1.5])\n",
    "plt.xlabel('net input $z$')\n",
    "plt.ylabel('activation $\\phi(z)$')\n",
    "plt.axhline(1, color='black', linestyle=':')\n",
    "plt.axhline(0.5, color='black', linestyle=':')\n",
    "plt.axhline(0, color='black', linestyle=':')\n",
    "plt.axhline(-0.5, color='black', linestyle=':')\n",
    "plt.axhline(-1, color='black', linestyle=':')\n",
    "\n",
    "plt.plot(z, tanh_act,\n",
    "         linewidth=3, linestyle='--',\n",
    "         label='tanh')\n",
    "\n",
    "plt.plot(z, log_act,\n",
    "         linewidth=3,\n",
    "         label='logistic')\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('images/13_03.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* The shapes of the two sigmoidal curves look very similar\n",
    "* however, the ``tanh`` function has 2× larger output space than the ``logistic`` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Note that we implemented the ``logistic`` and ``tanh`` functions verbosely for the purpose of illustration\n",
    "* In practice, we can use NumPy's ``tanh`` function to achieve the same results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "tanh_act = np.tanh(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In addition, the logistic function is available in SciPy's special module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "log_act = expit(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Rectified linear unit activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ``tanh`` and ``logistic`` activations suffer from **vanishing gradient problem**\n",
    "* This means the **derivative of activations** with respect to net input **diminishes** as $z$ becomes large\n",
    "* As a result, **learning weights during the training phase** become **very slow** because the gradient terms may be **very close to zero**\n",
    "* ReLU activation addresses this issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Mathematically, ReLU is defined as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/relu.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ReLU is still a nonlinear function that is good for learning complex functions with neural networks\n",
    "* Besides this, the derivative of ReLU, with respect to its input, is always 1 for positive input values\n",
    "* Therefore, it **solves** the problem of vanishing gradients, making it **suitable for deep neural networks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Vanishing gradient problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* backpropagation worked well with relatively shallow networks (one or two layers of hidden units (1980s)\n",
    "* but that as the networks got deeper, the networks either \n",
    "    - took an inordinate amount of time to train, or \n",
    "    - else they entirely failed to converge on a good set of weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_11b.jpg\" width=800/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Use of backpropagation to update weights **across many** layers \n",
    "    * this leads to vanishing gradient problem\n",
    "    * root of the problem: the gradient of a given layer is the **product** of gradients at **previous** layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Chain rule leading to vanishing gradient problem** (1)\n",
    "\n",
    "* Fundamentally, the backpropagation algorithm is an implementation of the chain rule from calculus\n",
    "* The chain rule involves the multiplication of terms\n",
    "* Backpropagating an error from one neuron back to another can involve multiplying the error by a number terms with values less than 1\n",
    "* These multiplications by values less than 1 happen repeatedly as the error signal gets passed back through the network\n",
    "* This results in the error signal becoming smaller and smaller as it is backpropagated through the network\n",
    "* Indeed, the error signal often diminishes exponentially with respect to the distance from the output layer\n",
    "* The effect of this diminishing error: the weights in the early layers of a deep network are often adjusted by only a tiny (or zero) amount during each training iteration\n",
    "* In other words: the early layers \n",
    "    - either train very, very slowly \n",
    "    - or do not move away from their random starting positions at all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Chain rule leading to vanishing gradient problem** (2)\n",
    "\n",
    "* However, the early layers in a neural network are vitally important to the success of the network\n",
    "* It is the neurons in these layers that learn to detect the features in the input\n",
    "* Later layers of the network use detected features as the fundamental building blocks of the representations \n",
    "* These building blocks ultimately determine the output of the network\n",
    "* The error signal that is backpropagated through the network is in fact the gradient of the error of the network\n",
    "* --> this problem of the error signal rapidly diminishing to near zero is known as the vanishing gradient problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Computation of error in hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_11c.png\" width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Compuation of gradients for updating weights of hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_07_11cc.png\" width=500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The sigmoid activation function and its derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_11d.jpg\" width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Problem with sigmoid function as activation function\n",
    "\n",
    "* The derivative becomes very small for large positive $z$ and large negative $z$\n",
    "* Derivative largest at $0.25$ for $z = 0$ (small value in itself)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The hyperbolic tangent activation function and its derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_11e.jpeg\" width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Problem with hyperbolic tanget function as activation function\n",
    "\n",
    "* The derivative becomes very small for large positive $z$ and large negative $z$\n",
    "* At least, derivative around $z = 0$ higher than for sigmoid activation function (maximum 1)\n",
    "* ==> Vanishing gradient problem still present, but maybe somewhat less severe than with sigmoid\n",
    "* Consequences\n",
    "    * same as for sigmoid activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Use of backpropagation to update weights **across many** layers \n",
    "    * ==> gradients for first layers may become very small (multiplication of many values < 1 for derivative of sigmoid and hyperbolic tanget activation functions) \n",
    "* Consequences\n",
    "    * long training times\n",
    "    * ==> weights of first layers change very little to not at all (many epochs needed to update weights)\n",
    "    * ==> in practice, only weights of last layers will be updated\n",
    "    * poor performance (poor learning performance of first layer influences learning of following layers)\n",
    "    * ==> learning of last layers depend on what first layers learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loss function: Cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* Cross entropy loss, or log loss, measures the **performance of a classification model** whose output represents a **probability**, that is, a value between 0 and 1. \n",
    "* Cross entropy loss **increases** as the predicted probability **diverges** from the actual label. So predicting a probability of for example .017 when the actual observation label is 1 would result in a **high** loss value. \n",
    "* A perfect model would have a log loss of 0. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Choice of cross entropy in Keras**\n",
    "\n",
    "* Binary classification problems: use binary cross entropy (``binary_crossentropy`` in Keras)\n",
    "* Multi-class classification problems: use categorical cross entropy (``categorical_crossentropy`` in Keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Binary cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/binary_logloss.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'log loss')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import math as m\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Define binary cross entropy\n",
    "def binary_crossEntropy(yHat, y):\n",
    "    term_1 = y * m.log(yHat)#; print(term_1)\n",
    "    term_2 = (1 - y) * m.log(1 - yHat)#; print(term_2)\n",
    "    \n",
    "    return -(term_1 + term_2)\n",
    "\n",
    "# Get values between 0 and 1 representing probabilities for which\n",
    "# we will compute log loss for\n",
    "values = np.linspace(0.001, .999, 999)\n",
    "\n",
    "# Compute log losses\n",
    "logloss = []\n",
    "for val in values:\n",
    "    logloss.append(binary_crossEntropy(val, 1))\n",
    "\n",
    "# Plot log loss, given that true class label is 1\n",
    "plt.plot(values, logloss, '.')\n",
    "plt.title(\"log loss when true class label = 1\")\n",
    "plt.xlabel(\"predicted probablility\")\n",
    "plt.ylabel(\"log loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Categorical cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/categorical_logloss.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./images/cross_entropy.png\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10536051565782628\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "\n",
    "# Define categorical cross entropy\n",
    "def categorical_crossEntropy(yHat, y):\n",
    "    return - np.sum(y * np.log(yHat))\n",
    "\n",
    "# Define some toy data\n",
    "y_pred = np.array([0.1, 0.9, 0.1])\n",
    "y = np.array([0, 1, 0])\n",
    "\n",
    "# Compute cross entropy\n",
    "ce = categorical_crossEntropy(y_pred, y)\n",
    "print(ce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/categorical_logloss.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Differences for Cross entropy:\n",
    "- **Binary Classification**:\n",
    "  - Two classes (0 or 1).\n",
    "  - One predicted probability for class 1.\n",
    "  - Loss is calculated for this single probability.\n",
    "\n",
    "- **Multiclass Classification**:\n",
    "  - More than two classes.\n",
    "  - Multiple predicted probabilities (one for each class).\n",
    "  - Loss is calculated over all classes, penalizing the model for the true class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things you have learned in this series of lectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Overview over different deep learning tools in using Python\n",
    "* Basic anatomy/architecture of ANN\n",
    "* How to build and train models for \n",
    "    * binary and multiclass classification\n",
    "    * regression with few samples using KFold cross validation\n",
    "* Choose appropriate activation functions for specific problems\n",
    "* Basic preprocessing of text data\n",
    "* Regularisation methods for ANN"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "nbpresent": {
   "slides": {
    "e1bcc92f-87ee-4cda-abb3-a53c55aa7d3b": {
     "id": "e1bcc92f-87ee-4cda-abb3-a53c55aa7d3b",
     "layout": "manual",
     "prev": null,
     "regions": {
      "20704684-44d7-4469-9fff-2966e85ae769": {
       "attrs": {
        "height": 0.8333333333333334,
        "pad": 0.01,
        "width": 0.8333333333333333,
        "x": 0.07091973498809348,
        "y": 0.09314162519826254
       },
       "id": "20704684-44d7-4469-9fff-2966e85ae769"
      },
      "8cdfe229-1ced-4a84-968c-11f4bdfb2807": {
       "attrs": {
        "height": 1,
        "pad": 0.01,
        "treemap:weight": 1,
        "width": 1,
        "x": 0,
        "y": 0
       },
       "id": "8cdfe229-1ced-4a84-968c-11f4bdfb2807"
      }
     }
    }
   },
   "themes": {}
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
