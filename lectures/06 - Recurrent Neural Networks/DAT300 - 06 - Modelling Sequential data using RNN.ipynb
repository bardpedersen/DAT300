{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Modelling Sequential Data using Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Introducing sequential data](#Introducing-sequential-data)\n",
    "    * [Representing sequences](#Representing-sequences)\n",
    "    * [The different categories of sequence modelling](#The-different-categories-of-sequence-modelling)\n",
    "* [RNN for modelling sequences](#RNN-for-modelling-sequences)\n",
    "    * [Structure and flow of RNNs](#Structure-and-flow-of-RNNs)\n",
    "    * [Computing activations in RNNs](#Computing-activations-in-RNNs)\n",
    "    \n",
    "* [Working with text data in Keras](#Working-with-text-data-in-Keras)\n",
    "    * [More on one-hot encoding](#More-on-one-hot-encoding) - Contains link to <font color=green>**COLAB NOTEBOOK 01**</font>\n",
    "    * [Word embeddings](#Word-embeddings) - Contains link to <font color=green>**COLAB NOTEBOOK 02**</font>\n",
    "* [More on RNNs](#More-on-RNNs)\n",
    "    * [Vanishing gradient problem](#Vanishing-gradient-problem)\n",
    "    * [LSTM units](#LSTM-units)\n",
    "    * [Using simple RNN and LSTM layers in Keras](#Using-simple-RNN-and-LSTM-layers-in-Keras) - Contains link to <font color=green>**COLAB NOTEBOOK 03**</font>\n",
    "    * [Advanced use of RNNs](#Advanced-use-of-RNNs) - Contains **multiple** links to <font color=green>**COLAB NOTEBOOKS**</font>\n",
    "    * [Sequence processing with CNN and RNN](#Sequence-processing-with-CNN) - Contains link to <font color=green>**COLAB NOTEBOOK**</font>\n",
    "* [Summary of RNN](#Summary-of-RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Artificial Neural Networks in DAT300**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* So far we have used ANN for various tasks\n",
    "    * Binary classification\n",
    "    * Multiclass classification\n",
    "    * Regression\n",
    "    * CNN for image data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* ANN for analysis of sequential data\n",
    "    * RNN for text data\n",
    "    * RNN for time series data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Classic approach to text classification: bag-of-words model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_00.PNG\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Classic approach to text classification: bag-of-words model**\n",
    "\n",
    "* is not an order-preserving tokenisation method\n",
    "* the tokens generated are understood as a set, not a sequence\n",
    "* general structure of sentence is lost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**n-grams for bag-of-words model**\n",
    "\n",
    "* n-grams are a powerful feature engineering tool\n",
    "* work well for shallow text processing\n",
    "* models using n-grams are lightweight compared to RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introducing sequential data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* So far we have worked with input data is **Independent and Identically Distributed (IID)**\n",
    "    * we have $n$ data samples: $x^{(1)}, x^{(2)}, \\dots, x^{(n)}$\n",
    "    * the order in which we use the data for training our machine learning algorithm does not matter\n",
    "* This assumption is **not valid anymore** when we deal with sequences — by definition, order matters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Applications of RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Document classification** and **timeseries classification**, such as identifying the topic of an article or the author of a book\n",
    "* **Timeseries comparisons**, such as estimating how closely related two documents or two stock tickers are\n",
    "* **Sequence-to-sequence** learning, such as decoding an English sentence into French\n",
    "* **Sentiment analysis**, such as classifying the sentiment of tweets or movie reviews as positive or negative\n",
    "* **Timeseries forecasting**, such as predicting the future weather at a certain location, given recent weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Representing sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We've established that sequences are a **non-independent order** in our input data\n",
    "* We next need to find ways to leverage this valuable information in our machine learning model\n",
    "* Sequences will be represented as \n",
    "    * $(x^{(1)}, x^{(2)}, \\dots, x^{(T)})$\n",
    "    * superscript indices indicate the **order** of the instances\n",
    "    * **length** of sequence is $T$\n",
    "    * **In time series**: each sample point $x^{(t)}$ belongs to a particular time $t$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Example\n",
    "\n",
    "* A time-series data where both $x$'s and $y$'s naturally follow the order according to their time axis\n",
    "* Therefore, both $x$'s and $y$'s are sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_07_01.PNG\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure from book **Python Machine Larning**, S. Raschka, V. Mirjalili, *Packt Publishing* (2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### RNN vs. other standard neural network models\n",
    "\n",
    "* Standard neural network models that we have covered so far, such as MLPs (dense NN) and CNNs, **are not capable** of handling the *order* of input samples\n",
    "* Intuitively, one can say that such models do not have a *memory* of the past seen samples\n",
    "* With previous standard NN, samples are passed through the feedforward and backpropagation steps, and the weights are updated *independent* of the order in which the sample is processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* RNNs, by contrast, are designed for modeling sequences\n",
    "* RNNs are capable of remembering past information and processing new events accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The different categories of sequence modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Different types of sequence modeling tasks require **appropriate** models\n",
    "* If **either** the input or output is a sequence, the data will form **one** of the following three different categories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_07_02.PNG\" width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure from book **Python Machine Larning**, S. Raschka, V. Mirjalili, *Packt Publishing* (2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **Many-to-one**\n",
    "    * *input data*: a sequence \n",
    "    * *output data*: a fixed-size vector, not a sequence\n",
    "    * *example*: **sentiment analysis**, where the input is textbased and the output is a class label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **One-to-many**: \n",
    "    * *input data*: standard format, not a sequence \n",
    "    * *output data*: a sequence \n",
    "    * *example*: **image captioning**, where the input is an image and the output is an English phrase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_02_a_image_captioning.png\" width=1300/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **Many-to-many**: \n",
    "    * *input data*: a sequence\n",
    "    * *output data*: a sequence \n",
    "    * *examples*: \n",
    "        * *synchronised*: **video classification**, where each frame in a video is labeled. \n",
    "        * *delayed*: **translating** a language into another. For instance, an entire English sentence must be read and processed by a machine before producing its translation into German."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## RNN for modelling sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Introduction of typcal RNN structure\n",
    "* Data flow through one or more hidden layers\n",
    "* Computation of neuron activations in a typical RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Structure and flow of RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A standard feedforward neural network and an RNN, in a side by side for comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_07_03.PNG\" width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure from book **Python Machine Larning**, S. Raschka, V. Mirjalili, *Packt Publishing* (2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Both networks have only one hidden layer\n",
    "* Generic RNN architecture corresponds to **two** modelling categories where input data is **sequence**\n",
    "    * **many-to-many**, where output $y^{(t)}$ is a sequence\n",
    "    * **many-to-one**, where only the last element of output sequence $y^{(t)}$ is used. $y^{(t)}$ can be converted into a standard, non-sequential unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **Standard feedforward network**: information flows from the input to the hidden layer, and then from the hidden layer to the output layer\n",
    "* **RNN**: \n",
    "    * hidden layer gets its input from both the input layer and the hidden layer from the previous time step\n",
    "    * flow of information in adjacent time steps in the hidden layer allows the network to have a memory of past events\n",
    "    * flow of information is usually displayed as a loop, also known as a **recurrent edge** in graph notation, which is how this general architecture got its name\n",
    "* **NOTE**: In Keras sequential models there is no such thing as input layer, only hidden layers and output layers\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Single layer RNN\n",
    "\n",
    "* **Standard neural networks**: unit in hidden layer receives only one input, that is the net preactivation associated with the input layer\n",
    "* **RNN**: units in hidden layer receives two distinct inputs:\n",
    "    * **preactivation** from **input** layer\n",
    "    * **activation** from **same** hidden layer from previous time step $t-1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_04.PNG\" width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure from book **Python Machine Larning**, S. Raschka, V. Mirjalili, *Packt Publishing* (2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multilayer RNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **layer=1**: the first hidden layer is represented as $h_{1}^{(t)}$ and gets its input from the data point $x^{(t)}$ and activations from the same hidden layer, but the previous time step $h_{1}^{(t-1)}$\n",
    "* **layer=2**: the second hidden layer $h_{2}^{(t)}$ receives its inputs (activations) from the hidden units of the layer below at the current time step $(h_{1}^{(t)})$ and its own activations form the same layer from the previous time step $h_{2}^{(t-1)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_07_05.PNG\" width=700/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure from book **Python Machine Larning**, S. Raschka, V. Mirjalili, *Packt Publishing* (2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Computing activations in RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Learn how to compute the activations of\n",
    "    * hidden layer\n",
    "    * output layer\n",
    "* Discuss computations for RNN with only one hidden layer\n",
    "* Same concept applies to multilayer RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Weight matrices in RNNs**\n",
    "\n",
    "* $W_{xh}$: weight matrix between input $x^{(t)}$ and hidden layer $h$\n",
    "* $W_{hh}$: weight matrix associated with recurrent edge\n",
    "* $W_{hy}$: weight matrix between hidden layer $h$ and output layer $y$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_06.PNG\" width=900/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure from book **Python Machine Larning**, S. Raschka, V. Mirjalili, *Packt Publishing* (2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Activation computations of hidden layer units**\n",
    "\n",
    "* net input: $z_{h}^{(t)}$\n",
    "* bias vector for hidden units: $\\bf{\\it{b_{h}}}$\n",
    "* activation function of hidden layer: $\\phi (\\cdot)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"./images/eq_07_00.PNG\" width=500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"./images/eq_07_01.PNG\" width=750/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_06.PNG\" width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Alternative activation computations of hidden layer units**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* concatenated weight matrix: $W_{h}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"./images/eq_07_02.PNG\" width=300/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"./images/eq_07_03.PNG\" width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_06.PNG\" width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Activation computations of output units**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* output: $y^{(t)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/eq_07_04.PNG\" width=500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_07_06.PNG\" width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Graphical illustration of activation computations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/eq_07_05.PNG\" width=1000/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure from book **Python Machine Larning**, S. Raschka, V. Mirjalili, *Packt Publishing* (2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Working with text data in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You have learned in previous lectures how to carry out **sentiment analysis** with **scikit-learn** and **Keras** using ANN with dense layers\n",
    "* Now you will learn how to work with and **preprocess** text in **Keras** before analysing it with RNN models built in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More on one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>**COLAB NOTEBOOK 01**</font>: code on how to do [one-hot encoding of words and characters](https://colab.research.google.com/drive/1UTb1k0zyGe5_j4bpPBrJ3bS9yORDORBY?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* One-hot encoding generates large sparse matrices (many zeros)\n",
    "* A vocabulary of 20 000 words results in a sparse matrix containing 20 000 features \n",
    "    * each word is represented by a vector of dimension 20 000\n",
    "    * each vector contains 19 999 zeros except one dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A more elegant way of representing words is **embedding**\n",
    "    * use finite-sized vectors to represent words\n",
    "    * these finite-sized vectors contain real numbers\n",
    "* Idea behind embedding\n",
    "    * embedding is a feature learning technique \n",
    "    * embedding automatically learns salient features to represent word in a dataset\n",
    "    * `embedding_size << unique_words` to represent the entire vocabulary\n",
    "as input features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Advantages of embedding over one-hot encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A reduction in the dimensionality of the feature space to decrease the effect of the curse of dimensionality\n",
    "* The extraction of salient features since the embedding layer in a neural network is trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_07_09.PNG\" width=700/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure from book **Python Machine Larning**, S. Raschka, V. Mirjalili, *Packt Publishing* (2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**A toy example of a word-embedding space**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Four words embedded in a 2D plane: *cat, dog, wolf, tiger*\n",
    "* There is a **semantic relationship** between the words\n",
    "* Semantic relationship can be encoded as **geometric transformation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**A toy example of a word-embedding space**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_07_10.PNG\" width=350/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **From pet to wild animal** vector\n",
    "    * from dog to wolf\n",
    "    * from cat to tiger\n",
    "* **From canine to feline** vector\n",
    "    * from dog/wolf to cat/tiger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**A toy example of a word-embedding space**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Assume cat, dog, wolf and tiger are part of a 50 000-word animal vocuabulary we want to work with\n",
    "* One-hot encoding: each of the four words would result in a 50 000-dimensional vector\n",
    "* In this embedding example with two vectors cat, dog, wolf and tiger may be represented meaningful with a 2-dimensional vector\n",
    "* Word vectors from embedding\n",
    "    * cat --> [0.7, 0.3]\n",
    "    * dog --> [0.4, 0.4]\n",
    "    * wolf  --> [0.4, 0.9]\n",
    "    * tiger --> [0.8, 0.8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_07_10.PNG\" width=250/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Real world embeddings**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common examples of meaningful geometric transformations are\n",
    "\n",
    "* \"gender\" vectors\n",
    "* \"plural\" vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples\n",
    "\n",
    "* By adding a “female” vector to the vector “king” we obtain the vector “queen”\n",
    "* By adding a “plural” vector, we obtain “kings”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Ways to obtain word embedding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Learn** word embeddings **jointly** with the main task you care about (such as document classification or sentiment prediction). In this setup, you start with random word vectors and then learn word vectors in the same way you learn the weights of a neural network.\n",
    "* **Load into your model** word embeddings that were **precomputed** using a different machine-learning task than the one you’re trying to solve. These are called *pretrained word embeddings*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretrained word embeddings\n",
    " * [GloVe](https://nlp.stanford.edu/projects/glove/)  (Global Vectors for Word Representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example of how to work with word embeddings in Keras**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>**COLAB NOTEBOOK 02**</font>: code on how to use [word embeddings](https://colab.research.google.com/drive/16Mrqyj7NUFMALPf1-BxpYkpzOzCtSYgT?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## More on RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section discusses\n",
    "\n",
    "* Vanishing gradient problem\n",
    "* Layers that can handle the vanishing gradient problem\n",
    "* Advanced use of recurrent networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Vanishing gradient problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_11b.png\" width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Use of backpropagation to update weights **across many** layers \n",
    "    * this leads to vanishing gradient problem\n",
    "    * root of the problem: the gradient of a given layer is the **product** of gradients at **previous** layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Computation of error in hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_11c.png\" width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compuation of gradients for updating weights of hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_07_11cc.png\" width=500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The sigmoid activation function and its derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_11d.jpg\" width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The hyperbolic tangent activation function and its derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_11e.jpeg\" width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Vanishing gradient problem with RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RNNs should **theoretically** be able to retain at time $t$ information about inputs seen many timesteps before\n",
    "* In practice, such long-term dependencies are **impossible to learn** because of **vanishing gradient problem** (more on this on next slides)\n",
    "* Therefore RNNs are **too simplistic** for real use and other more advanced model types are required (like LSTM or GRU units)\n",
    "* See illustration article [Visualizing memorization in RNNs](https://distill.pub/2019/memorization-in-rnns/) at Distill.pub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_11f.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Image source @GitHub by Raschka](https://github.com/rasbt/stat479-deep-learning-ss19/blob/master/L14_intro-rnn/L14_intro-rnn-part2_slides.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_11g.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_11h.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_11i.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_11j.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_11k.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_11l.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Solution**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various solutions exist such as\n",
    "\n",
    "* **Gradient clipping (solves exploding gradients)**\n",
    "    - set a max value for gradients if they grow too large\n",
    "    - setting a max value solves only exploding gradient problem\n",
    "* **Truncated Backpropagation through time (TBPTT)**\n",
    "    - limit the number of time steps the signal can backpropagate each forward pass\n",
    "    - Example: even if sequence has 100 elements / steps, only backpropagate through fewer steps\n",
    "* **Long-Short-Term-Memory (LSTM) units (most common)**\n",
    "    - Architecture that avoids vanishing / exploding gradient problems\n",
    "    - Sepp Hochreiter and Jürgen Schmidhuber, Long short-term memory, *Neural computation*, 9, no. 8, (1997): 1735 - 1780"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LSTM units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LSTMs were introduced and **designed to overcome** the vanishing gradient problem\n",
    "* LSTM adds a way to carry information **across many timesteps**\n",
    "* In this way LSTM **saves information for later**, thus **preventing older signals** from gradually vanishing during processing by re-injecting past information from previous layers \n",
    "* The building block of an LSTM is a **memory** cell, which essentially represents the hidden layer\n",
    "* Unfolded structure of a **modern** LSTM cell is shown on next slide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_12a.png\" width=1000/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_12.PNG\" width=850/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $\\bf{C}^{(t-1)}$: cell state at previous time step $t-1$\n",
    "* $\\oplus$: elementwise addition\n",
    "* $\\odot$: elementwise multiplication\n",
    "* $\\bf{h}^{(t-1)}$: hidden units activation at previous time step $t-1$\n",
    "* $\\bf{x}^{(t)}$: input data at current time step $t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Alternative presentation of LSTM. Note that $g$ here is represented by $\\widetilde{C}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_12_alt.PNG\" width=850/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_12b.png\" width=1000/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_12c.png\" width=1000/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_12d.png\" width=1000/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Forget gate** $f_{t}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Allows the memory cell to reset the cell state $\\bf{C}$ to avoid $\\bf{C}$ growing indefinitively\n",
    "* Decides which information is allowed to go through and which information to suppress (controls how much of the old cell value is used in the new cell value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_07_13.PNG\" width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_12e.png\" width=1000/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Input gate** $i_{t}$ and **input node** $g_{t}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Input gate $i_{t}$ and input node $g_{t}$ are responsible for updating the cell state $\\bf{C}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_07_14.PNG\" width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_12f.png\" width=1000/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Computation of cell state** $\\bf{C}^{(t)}$ **at time step** $t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_07_15.PNG\" width=500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Output gate** $o_{t}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Output gate $o_{t}$ decides how to update the values of hidden units (controls how much of the new cell value is outputted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_07_16.PNG\" width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_12g.png\" width=1000/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Computation of hidden units activations** $\\bf{h}^{(t)}$ **at time step** $t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_07_17.PNG\" width=500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_12h.png\" width=1400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Further reading on LSTM**\n",
    "\n",
    "* [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/?source=post_page-----37e2f46f1714----------------------)\n",
    "* [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### GRU units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gated Recurrent Units (GRU)\n",
    "* GRUs have a simpler architecture than LSTMs \n",
    "    * fewer parameters\n",
    "    * ==> computationally more efficient\n",
    "    * for some tasks performance comparable to those of LSTM\n",
    "* There are reports exhibiting that GRUs have better performance on smaller datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using simple RNN and LSTM layers in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>**COLAB NOTEBOOK 03**</font>: code on how to do [use simple RNN and LSTM layers in Keras](https://colab.research.google.com/drive/1d1d4KdN-3_IizrO98L6e3VAwOE11f6mT?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Weights in RNN using LSTM units**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<font color=green>**COLAB NOTEBOOK 04**</font>: code on [how to determine LSTM weights](https://colab.research.google.com/drive/14GzWAUpCevvjAVKoJomUS56oxMPnOzo7?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>**COLAB NOTEBOOK 05.6**</font>: code on [bidirectional RNN](https://colab.research.google.com/drive/1QlbhgsXpaVQtE0sgWS_yP5OKc1K0yY-Z?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Advanced use of RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways to improve the performance and generalisation power of RNNs.\n",
    "\n",
    "* **Recurrent dropout** - This is a specific, built-in way to use dropout to fight overfitting in recurrent layers\n",
    "* **Stacking recurrent layers** - This increases the representational power of the network (at the cost of higher computational loads)\n",
    "* **Bidirectional recurrent layers** - These present the same information to a recurrent network in different ways, increasing accuracy and mitigating forgetting issues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All three concepts will be discussed by applying them to a **temperature-forecasting** problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**A temperature-forecasting problem**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* So far, the only sequence data covered were text data\n",
    "* In the following examples timeseries data will be used (weather timeseries)\n",
    "* Weather data recorded at the [Max Planck Institute for Biogeochemistry](https://www.bgc-jena.mpg.de/wetter/) in Jena, Germany\n",
    "    * 14 different quantities measured (such as air temperature, atmospheric pressure, wind direction, etc.)\n",
    "    * Recorded every 10 minutes across many years\n",
    "    * Original data goes back to 2003\n",
    "    * Data used in examples: 2009 - 2016\n",
    "* Use data to build model that:\n",
    "    * takes as input data from recent past\n",
    "    * predicts air temperature 24 hours in future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Some Colab notebooks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>**COLAB NOTEBOOK 05.1**</font>: code on [time series data generator](https://colab.research.google.com/drive/1j1-nT4fdVCUnLUZsoAO5GHhGUH8-1m1F?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>**COLAB NOTEBOOK 05.2**</font>: code on [ANN with dense layers for time series data](https://colab.research.google.com/drive/1zNplubUnorV1othZXe_LmvXkxgqsUcRP?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>**COLAB NOTEBOOK 05.3**</font>: code on [baseline RNN for time series data](https://colab.research.google.com/drive/1nyfR5WXyICwKhFccJ2CmQgjJs4F33DsS?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>**COLAB NOTEBOOK 05.4**</font>: code on [RNN with dropout for time series data](https://colab.research.google.com/drive/1Uw4rCu7WmufOmHTzgu9Fla-zfocS_bug?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>**COLAB NOTEBOOK 05.5**</font>: code on [stacked RNN for time series data](https://colab.research.google.com/drive/1EV1MET240mJlS6_xhzr1pMggNxp391pT?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>**COLAB NOTEBOOK 05.6**</font>: code on [bidirectional RNN](https://colab.research.google.com/drive/1QlbhgsXpaVQtE0sgWS_yP5OKc1K0yY-Z?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sequence processing with CNN and RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Previously learned properties of CNN**\n",
    "\n",
    "* Perform particularly well on computer vision problems\n",
    "    * ability to operate **convolutionally**\n",
    "    * **extracting features** from **local input patches**\n",
    "    * allowing for **representation modularity** and **data efficiency**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **Same properties** that make CNNs excel at computer vision also make them **highly relevant to sequence processing**\n",
    "* Time can be treated as a **spatial dimension**, like the height or width of a 2D image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* 1D convnets can be **competitive** with RNN's on **certain** sequence-processing problems usually at a **considerably cheaper computational cost**\n",
    "* **Small** 1D convnets can offer a **fast alternative** to RNN s for **simple tasks** such as **text classification** and **timeseries forecasting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Understanding 1D convolution for sequence data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1D convolutions extract local 1D patches (subsequences) from sequences\n",
    "* Such 1D convolution layers can recognize local patterns in a sequence\n",
    "* Same input transformation is performed on every patch\n",
    "* ==> A pattern learned at a certain position in a sentence can later be recognized at a different position\n",
    "* ==> Makes 1D convnets translation invariant (for temporal translations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Example: \n",
    "\n",
    "* a 1D convnet processing **sequences of characters** using **convolution windows** of size 5 should be able to learn **words or word fragments of length 5 or less**\n",
    "* should be able to **recognise** these words **in any context** in an **input sequence**\n",
    "* ==> A **character-level** 1D convnet is thus able to learn about **word morphology**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/fig_07_21.png\" width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure from book **Deep Learning with Python**, Francois Chollet, *Manning Publications* (2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1D pooling for sequence data**\n",
    "\n",
    "* Previously learned about 2D pooling operations, such as 2D average pooling and max pooling, used in convnets to spatially downsample image tensors\n",
    "* 2D pooling operation has a 1D equivalent\n",
    "    * extracting 1D patches (subsequences) from an input\n",
    "    * outputting the maximum value (max pooling) or average value (average pooling)\n",
    "* Just as with 2D convnets, this is used for reducing the length of 1D inputs (subsampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure from book **Deep Learning with Python**, Francois Chollet, *Manning Publications* (2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<font color=green>**COLAB NOTEBOOK**</font>: code on [how to do sequence processing with CNN and RNN](https://colab.research.google.com/drive/1k705LQR6DN8_MEZxndsMXWBa5CHF6idr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./images/fig_07_22.png\" width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure from book **Deep Learning with Python**, Francois Chollet, *Manning Publications* (2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary of RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learned the following techniques, which are widely applicable to any dataset of sequence data, from text to timeseries\n",
    "\n",
    "* How to tokenize text\n",
    "* What word embeddings are, and how to use them\n",
    "* What recurrent networks are, and how to use them\n",
    "* How to stack RNN layers and use bidirectional RNNs to build more-powerful sequence-processing models\n",
    "* How to use 1D convnets for sequence processing\n",
    "* How to combine 1D convnets and RNNs to process long sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Summary of RNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "RNNs can be used for\n",
    "\n",
    "* timeseries regression (“predicting the future”)\n",
    "* timeseries classification\n",
    "* anomaly detection in timeseries\n",
    "* sequence labeling (such as identifying names or dates in sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Summary of RNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1D CNN can be used for\n",
    "\n",
    "* machine translation (sequence-to-sequence convolutional models, like SliceNet)\n",
    "* document classification\n",
    "* spelling correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Importance of global order**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* If **global order matters** in your sequence data, then it’s preferable to use a **recurrent network** to process it\n",
    "* This is typically the case for timeseries, where the **recent past** is likely to be **more informative** than the **distant past**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* If **global ordering isn’t fundamentally meaningful**, then 1D convnets will turn out to work at least as well and are cheaper\n",
    "* This is often the case for text data, where a keyword found at the **beginning** of a sentence is **just as meaningful** as a keyword found **at the end**"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
